"""ç®€åŒ–çš„LangGraphçˆ¬è™«å·¥ä½œæµ"""
import os
from typing import TypedDict, Annotated
from dotenv import load_dotenv
# å¯¼å…¥ä¸åŸç‰ˆä¸€è‡´çš„å·¥å…·å‡½æ•°

from langchain_core.messages import BaseMessage
from langchain_openai import ChatOpenAI
# from langchain_community.chat_models import ChatOpenAI
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode, tools_condition


# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()
from file_tool import save_file, read_file, list_files, read_files
from jina_tool import jina_url_reader, jina_search
from free_web_tool import free_url_reader, free_search
from time_tool import get_current_time, get_time_info

class State(TypedDict):
    """ç®€å•çš„çŠ¶æ€å®šä¹‰"""
    messages: Annotated[list[BaseMessage], add_messages]

# åˆå§‹åŒ–LLM
llm = ChatOpenAI(
    # model="Qwen/Qwen3-14B",
    # model='Qwen/Qwen2.5-14B-Instruct',
    model='Qwen/Qwen3-30B-A3B-Instruct-2507',
    # base_url="https://api.siliconflow.cn/v1",
    # api_key=os.getenv("OPENAI_API_KEY"),

    base_url='https://api-inference.modelscope.cn/v1',
    api_key='ms-a0ff81a2-f678-40ca-9932-1279430f8d5e',
    temperature=0.0,
    max_tokens=2000,
    # streaming=False,
    extra_body={
        "enable_thinking": False,
    }
)

# å®šä¹‰å·¥å…· - ä½¿ç”¨ä¸åŸç‰ˆä¸€è‡´çš„å‡½æ•°åï¼ŒåŠ ä¸Šå…è´¹æ›¿ä»£å·¥å…·å’Œæ—¶é—´å·¥å…·
tools = [save_file, read_file, list_files, read_files, free_url_reader, free_search, get_current_time, get_time_info]
# tools = [save_file, read_file, list_files, read_files, free_url_reader, free_search]
llm_with_tools = llm.bind_tools(tools)

def chatbot(state: State):
    """èŠå¤©æœºå™¨äººèŠ‚ç‚¹ - æ·»åŠ ç»“æŸé€»è¾‘å’Œä¸Šä¸‹æ–‡ç®¡ç†"""
    messages = state["messages"]
    
    # ä¸Šä¸‹æ–‡ç®¡ç†ï¼šå¦‚æœæ¶ˆæ¯è¿‡å¤šï¼Œä¿ç•™æœ€æ–°çš„å‡ æ¡
    # if len(messages) > 10:
    #     # ä¿ç•™ç”¨æˆ·çš„åˆå§‹ä»»åŠ¡å’Œæœ€è¿‘çš„5è½®å¯¹è¯
    #     initial_message = messages[0]  # ç”¨æˆ·çš„åˆå§‹ä»»åŠ¡
    #     recent_messages = messages[-8:]  # æœ€è¿‘çš„8æ¡æ¶ˆæ¯ï¼ˆçº¦4è½®å¯¹è¯ï¼‰
    #     managed_messages = [initial_message] + recent_messages
    #     print(f"ğŸ“ ä¸Šä¸‹æ–‡ç®¡ç†ï¼šä¿ç•™ {len(managed_messages)} æ¡æ¶ˆæ¯ï¼ˆåŸ {len(messages)} æ¡ï¼‰")
    # else:
    #     managed_messages = messages
    
    # response = llm_with_tools.invoke(managed_messages)
    response = llm_with_tools.invoke(messages)

    # æ£€æŸ¥æ˜¯å¦åº”è¯¥ç»“æŸå¯¹è¯
    if response.content and any(keyword in response.content.lower() for keyword in 
                               ["ä»»åŠ¡å®Œæˆ", "å®Œæˆä»»åŠ¡", "å·²å®Œæˆ", "ç»“æŸ", "finished", "done"]):
        # å¦‚æœAIè¡¨ç¤ºä»»åŠ¡å®Œæˆï¼Œåˆ™ä¸è°ƒç”¨å·¥å…·
        response.tool_calls = []
        print("ğŸ¯ AIè¡¨ç¤ºä»»åŠ¡å®Œæˆï¼Œå‡†å¤‡ç»“æŸå¯¹è¯")
    
    return {"messages": [response]}
def should_continue(state: State):
    """å†³å®šæ˜¯å¦ç»§ç»­æ‰§è¡Œæˆ–ç»“æŸ"""
    messages = state["messages"]
    last_message = messages[-1]
    
    # å¦‚æœæœ‰å·¥å…·è°ƒç”¨ï¼Œç»§ç»­æ‰§è¡Œå·¥å…·
    if hasattr(last_message, 'tool_calls') and last_message.tool_calls:
        return "tools"
    
    # å¦‚æœæ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œç»“æŸå¯¹è¯
    return "end"

# æ„å»ºå›¾
graph_builder = StateGraph(State)
graph_builder.add_node("chatbot", chatbot)
graph_builder.add_node("tools", ToolNode(tools))

graph_builder.add_conditional_edges(
    "chatbot",
    should_continue,
    {
        "tools": "tools",
        "end": END
    }
)

graph_builder.add_edge("tools", "chatbot")  # ä¿®å¤ï¼šå·¥å…·æ‰§è¡Œåå›åˆ°chatbot
graph_builder.add_edge(START, "chatbot")

graph = graph_builder.compile()

def save_graph_visualization():
    """ç”Ÿæˆå¹¶ä¿å­˜LangGraphçš„å¯è§†åŒ–å›¾å½¢"""
    try:
        # å°è¯•ç”ŸæˆMermaidå›¾å¹¶ä¿å­˜ä¸ºPNG
        png_data = graph.get_graph().draw_mermaid_png()
        with open("langgraph_structure.png", "wb") as f:
            f.write(png_data)
        print("âœ… å›¾å½¢ç»“æ„å·²ä¿å­˜ä¸º 'langgraph_structure.png'")
        
        # å¦‚æœåœ¨Jupyterç¯å¢ƒä¸­ï¼Œå°è¯•æ˜¾ç¤ºå›¾ç‰‡
        try:
            try:
                from IPython.display import Image, display
                display(Image(png_data))
                print("âœ… å›¾å½¢ç»“æ„å·²åœ¨notebookä¸­æ˜¾ç¤º")
            except ImportError:
                print("ğŸ’¡ æœªæ£€æµ‹åˆ°IPythonï¼Œå›¾ç‰‡å·²ä¿å­˜åˆ°æ–‡ä»¶")
        except Exception as e:
            print(f"ğŸ’¡ åœ¨æ™®é€šPythonç¯å¢ƒä¸­è¿è¡Œï¼Œå›¾ç‰‡å·²ä¿å­˜åˆ°æ–‡ä»¶ï¼Œé”™è¯¯ä¿¡æ¯: {e}")
            
    except ImportError as e:
        print(f"âŒ ç¼ºå°‘ä¾èµ–åŒ…: {e}")
        print("ğŸ’¡ è¯·å®‰è£…: pip install pygraphviz æˆ– pip install graphviz")
    except Exception as e:
        print(f"âŒ ç”Ÿæˆå›¾å½¢æ—¶å‡ºé”™: {e}")
        print("ğŸ’¡ å¦‚æœæ‚¨æƒ³æŸ¥çœ‹å›¾å½¢ç»“æ„ï¼Œè¯·ç¡®ä¿å®‰è£…äº†graphvizç›¸å…³ä¾èµ–")

# å°è¯•ç”Ÿæˆå›¾å½¢
print("ğŸ”„ æ­£åœ¨ç”ŸæˆLangGraphç»“æ„å›¾...")
save_graph_visualization()


def run_crawler(task: str):
    """è¿è¡Œçˆ¬è™«ä»»åŠ¡"""
    print(f"ğŸš€ å¼€å§‹æ‰§è¡Œä»»åŠ¡: {task}")
    
    messages = [{"role": "user", "content": task}]
    
    for event in graph.stream({"messages": messages}):
        for value in event.values():
            if "messages" in value and value["messages"]:
                message = value["messages"][-1]
                if hasattr(message, 'content') and message.content:
                    print(f"ğŸ¤– AI: {message.content}")
                if hasattr(message, 'tool_calls') and message.tool_calls:
                    for tool_call in message.tool_calls:
                        print(f"ğŸ”§ è°ƒç”¨å·¥å…·: {tool_call['name']}")

def run_crawler_debug(task: str):
    """è°ƒè¯•ç‰ˆçˆ¬è™«ä»»åŠ¡æ‰§è¡Œå™¨"""
    print(f"ğŸš€ å¼€å§‹æ‰§è¡Œä»»åŠ¡: {task}")
    
    messages = [{"role": "user", "content": task}]
    step_count = 0
    
    for event in graph.stream({"messages": messages}):
        step_count += 1
        print(f"\n{'='*50}")
        print(f"ğŸ“ æ‰§è¡Œæ­¥éª¤ {step_count}")
        print(f"{'='*50}")
        
        for node_name, value in event.items():
            print(f"ğŸƒ å½“å‰èŠ‚ç‚¹: {node_name}")
            
            if "messages" in value and value["messages"]:
                message = value["messages"][-1]
                
                # æ˜¾ç¤ºAIçš„æ–‡æœ¬å›å¤
                if hasattr(message, 'content') and message.content:
                    print(f"ğŸ¤– AI: {message.content}")
                
                # è¯¦ç»†æ˜¾ç¤ºå·¥å…·è°ƒç”¨
                if hasattr(message, 'tool_calls') and message.tool_calls:
                    print(f"\nğŸ”§ è®¡åˆ’è°ƒç”¨çš„å·¥å…·:")
                    for i, tool_call in enumerate(message.tool_calls, 1):
                        tool_name = tool_call.get('name', 'unknown')
                        tool_args = tool_call.get('args', {})
                        print(f"  {i}. {tool_name}")
                        print(f"     å‚æ•°: {tool_args}")
                
                # æ˜¾ç¤ºå·¥å…·æ‰§è¡Œç»“æœ
                if hasattr(message, 'tool_call_id'):
                    print(f"âœ… å·¥å…·æ‰§è¡Œå®Œæˆ: {message.name if hasattr(message, 'name') else 'unknown'}")
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯å·¥å…·èŠ‚ç‚¹çš„è¾“å‡º
            if node_name == "tools" and "messages" in value:
                tool_messages = value["messages"]
                for tool_msg in tool_messages:
                    if hasattr(tool_msg, 'name'):
                        print(f"ğŸ› ï¸ å·¥å…· {tool_msg.name} æ‰§è¡Œå®Œæˆ")
                        if hasattr(tool_msg, 'content'):
                            print(f"    ç»“æœ: {tool_msg.content[:100]}...")


if __name__ == "__main__":
    # 36krçˆ¬è™«ä»»åŠ¡ - ä½¿ç”¨å…è´¹å·¥å…·æ›¿ä»£
    task = """
ä»36kråˆ›æŠ•å¹³å°https://pitchhub.36kr.com/financing-flashæŠ“å–æ‰€æœ‰åˆåˆ›ä¼ä¸šèèµ„çš„ä¿¡æ¯;
ä¸‹é¢æ˜¯ä¸€ä¸ªå¤§è‡´æµç¨‹, ä½ æ ¹æ®æ¯ä¸€æ­¥çš„è¿è¡Œç»“æœå¯¹å½“å‰è®¡åˆ’ä¸­çš„ä»»åŠ¡åšå‡ºé€‚å½“è°ƒæ•´:
- çˆ¬å–å¹¶ä¿å­˜urlå†…å®¹ï¼Œä¿å­˜ä¸º36kr_finance_date.mdæ–‡ä»¶, dateæ˜¯å½“å‰æ—¥æœŸ;
- ç†è§£mdæ–‡ä»¶ï¼Œç­›é€‰æœ€è¿‘3å¤©çš„åˆåˆ›ä¼ä¸šèèµ„å¿«è®¯, æ‰“å°å‰5ä¸ªï¼Œéœ€è¦æå–å¿«è®¯çš„æ ¸å¿ƒä¿¡æ¯ï¼ŒåŒ…æ‹¬æ ‡é¢˜ã€é“¾æ¥ã€æ—¶é—´ã€èèµ„è§„æ¨¡ã€èèµ„é˜¶æ®µç­‰;
- å°†å…¨éƒ¨ç»“æœä½¿ç”¨è‡ªç„¶è¯­è¨€å­˜åœ¨æœ¬åœ°search_result_date.mdä¸­,dateæ˜¯å½“å‰æ—¥æœŸ;
"""   
    run_crawler(task)
    # run_crawler_debug(task)
