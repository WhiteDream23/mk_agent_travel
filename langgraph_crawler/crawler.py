"""ç®€åŒ–çš„LangGraphçˆ¬è™«å·¥ä½œæµ"""
import os
from typing import TypedDict, Annotated
from dotenv import load_dotenv
# å¯¼å…¥ä¸åŸç‰ˆä¸€è‡´çš„å·¥å…·å‡½æ•°

from langchain_core.messages import BaseMessage
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode, tools_condition


# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()
from file_tool import save_file, read_file, list_files, read_files
from jina_tool import jina_url_reader, jina_search

class State(TypedDict):
    """ç®€å•çš„çŠ¶æ€å®šä¹‰"""
    messages: Annotated[list[BaseMessage], add_messages]

# åˆå§‹åŒ–LLM
llm = ChatOpenAI(
    model="Qwen/Qwen3-8B",
    base_url="https://api.siliconflow.cn/v1",
    api_key=os.getenv("OPENAI_API_KEY"),
    # base_url='https://api-inference.modelscope.cn/v1/',
    # api_key='ms-848fbf20-9a26-4490-8bc5-a87f7ccf7ddf', 
    temperature=0.7,
    max_tokens=2000
)

# å®šä¹‰å·¥å…· - ä½¿ç”¨ä¸åŸç‰ˆä¸€è‡´çš„å‡½æ•°å
tools = [save_file, read_file, list_files, read_files, jina_url_reader, jina_search]
llm_with_tools = llm.bind_tools(tools)

def chatbot(state: State):
    """èŠå¤©æœºå™¨äººèŠ‚ç‚¹ - æ·»åŠ ç»“æŸé€»è¾‘"""
    response = llm_with_tools.invoke(state["messages"])
    
    # æ£€æŸ¥æ˜¯å¦åº”è¯¥ç»“æŸå¯¹è¯
    if response.content and any(keyword in response.content.lower() for keyword in 
                               ["ä»»åŠ¡å®Œæˆ", "å®Œæˆä»»åŠ¡", "å·²å®Œæˆ", "ç»“æŸ", "finished", "done"]):
        # å¦‚æœAIè¡¨ç¤ºä»»åŠ¡å®Œæˆï¼Œåˆ™ä¸è°ƒç”¨å·¥å…·
        response.tool_calls = []
    
    return {"messages": [response]}
def should_continue(state: State):
    """å†³å®šæ˜¯å¦ç»§ç»­æ‰§è¡Œæˆ–ç»“æŸ"""
    messages = state["messages"]
    last_message = messages[-1]
    
    # å¦‚æœæœ‰å·¥å…·è°ƒç”¨ï¼Œç»§ç»­æ‰§è¡Œå·¥å…·
    if hasattr(last_message, 'tool_calls') and last_message.tool_calls:
        return "tools"
    
    # å¦‚æœæ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œç»“æŸå¯¹è¯
    return "end"

# æ„å»ºå›¾
graph_builder = StateGraph(State)
graph_builder.add_node("chatbot", chatbot)
graph_builder.add_node("tools", ToolNode(tools))

graph_builder.add_conditional_edges(
    "chatbot",
    should_continue,
    {
        "tools": "tools",
        "end": END
    }
)

graph_builder.add_edge("tools", "chatbot")
graph_builder.add_edge(START, "chatbot")

graph = graph_builder.compile()

def run_crawler(task: str):
    """è¿è¡Œçˆ¬è™«ä»»åŠ¡"""
    print(f"ğŸš€ å¼€å§‹æ‰§è¡Œä»»åŠ¡: {task}")
    
    messages = [{"role": "user", "content": task}]
    
    for event in graph.stream({"messages": messages}):
        for value in event.values():
            if "messages" in value and value["messages"]:
                message = value["messages"][-1]
                if hasattr(message, 'content') and message.content:
                    print(f"ğŸ¤– AI: {message.content}")
                if hasattr(message, 'tool_calls') and message.tool_calls:
                    for tool_call in message.tool_calls:
                        print(f"ğŸ”§ è°ƒç”¨å·¥å…·: {tool_call['name']}")
                        # 1. ä½¿ç”¨jina_searchæœç´¢"36kråˆ›æŠ•èèµ„"
if __name__ == "__main__":
    # 36krçˆ¬è™«ä»»åŠ¡ - ä½¿ç”¨ç®€åŒ–çš„æœç´¢æŸ¥è¯¢
    task = """
ä»36kråˆ›æŠ•å¹³å°æŠ“å–åˆåˆ›ä¼ä¸šèèµ„ä¿¡æ¯:

å¯ç”¨å·¥å…·ï¼š
- jina_search: æœç´¢ç½‘é¡µå†…å®¹
- jina_url_reader: è¯»å–æŒ‡å®šURLçš„å†…å®¹ï¼ˆè‡ªåŠ¨ä¿å­˜æ–‡ä»¶ï¼‰
- save_file: ä¿å­˜å†…å®¹åˆ°æ–‡ä»¶
- read_file: è¯»å–æ–‡ä»¶å†…å®¹
- list_files: åˆ—å‡ºæ–‡ä»¶
- read_files: è¯»å–ç›®å½•ä¸­æ‰€æœ‰æ–‡ä»¶

ä»»åŠ¡æµç¨‹ï¼š
1. ä½¿ç”¨jina_searchæœç´¢"36kråˆ›æŠ•å¹³å°"
2. ä»æœç´¢ç»“æœä¸­æ‰¾åˆ°36krç›¸å…³é¡µé¢çš„URL
3. ä½¿ç”¨jina_url_readerè¯»å–URLå†…å®¹ï¼ˆä¼šè‡ªåŠ¨ä¿å­˜ï¼‰
4. ä½¿ç”¨read_fileè¯»å–ä¿å­˜çš„æ–‡ä»¶
5. åˆ†æå†…å®¹ï¼Œæå–æœ€è¿‘çš„èèµ„ä¿¡æ¯ï¼ˆå…¬å¸åã€èèµ„é‡‘é¢ã€è½®æ¬¡ã€æ—¶é—´ï¼‰
6. ä½¿ç”¨save_fileä¿å­˜åˆ†æç»“æœä¸º36kr_finance_report.md

é‡è¦æç¤ºï¼š
1. å®Œæˆæ‰€æœ‰æ­¥éª¤åï¼Œè¯·æ˜ç¡®è¯´æ˜"ä»»åŠ¡å®Œæˆ"
2. ä¸è¦é‡å¤æ‰§è¡Œç›¸åŒçš„æ“ä½œ
"""   
    run_crawler(task)
